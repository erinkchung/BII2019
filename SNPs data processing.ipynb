{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNPs in 70 possible PFAS associated genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct gene profile array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape bookmarked gnomAD pages for gene names and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open('gnomad bookmarks.html'))\n",
    "links = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make 2D array of gene profiles with [gene name, gene ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_profiles = []\n",
    "for link in links:\n",
    "    gene_info = [[link.text[:-9], link.get('href')[39:54]]]\n",
    "    gene_profiles += gene_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make array of corresponding CSV filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_files = os.listdir('geneCSVs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add corresponding CSV filename to gene profile [gene name, gene ID, corresponding file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene_profile in gene_profiles:\n",
    "    for gene_file in gene_files:\n",
    "        if gene_profile[1] in gene_file[14:29]:\n",
    "            gene_profile += [str(gene_file)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data into dataframe(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop over profiles, read corresponding CSV into DF, load DFs into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_variant_tables = []\n",
    "for gene_profile in gene_profiles:\n",
    "    table = pd.read_csv('geneCSVs/' + gene_profile[2])\n",
    "    table['gene'] = gene_profile[0]\n",
    "    table['geneID'] = gene_profile[1]\n",
    "    table.set_index('gene', inplace = True)\n",
    "    gene_variant_tables += [table]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenate dataframes, keeping gene names as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = gene_variant_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write text file list of rsIDs (column index 2) for batch querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make rsID array from column in main data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsIDlist = []\n",
    "for x in range(len(complete_table.values)):\n",
    "    rsIDlist += [complete_table.values[x][2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write rsID array to lines in text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listrsIDs.txt', 'w') as IDfile:\n",
    "    for ID in rsIDlist:\n",
    "        IDfile.write(\"%s\\n\" % ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(use text file for PolyPhen-2 batch query at http://genetics.bwh.harvard.edu/pph2/bgi.shtml and SIFT prediction query at https://sift.bii.a-star.edu.sg/www/SIFT_dbSNP.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare main dataframe for adding PolyPhen-2 and SIFT annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make columns for PolyPhen-2 score, PolyPhen-2 prediction, SIFT score, and SIFT prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table['SIFT_prediction'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table['PPH2_prediction'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare array with rsIDs, referenceNTs, alternateNTs, SIFT predictions, and PolyPhen-2 predictons - SNPs prediction profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(obtain SIFT results in html file - scrape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape rsID, reference nucleotide, alternate nucleotide, and SIFT prediction into SIFT profiles 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open('SIFT-scores.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = soup.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFT_profiles = []\n",
    "for row in rows[1:]:\n",
    "    profile = [row.find_all('td')[0].text, \\\n",
    "    row.find_all('td')[4].text, \\\n",
    "    row.find_all('td')[5].text, \\\n",
    "    row.find_all('td')[15].text]\n",
    "    # rsID, referenceNT, alternateNT, SIFTprediction\n",
    "    SIFT_profiles += [profile]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(obtain PolyPhen-2 results in tab separated text file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add PolyPhen-2 predictions into prediction profiles array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pph2_data = pd.read_csv('pph2-full.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean the spaces (there are so many wow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(pph2_data.values)):\n",
    "    for column in range(len(pph2_data.columns)):\n",
    "        pph2_data.iloc[row,column] = str(pph2_data.iloc[row,column]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rsID, reference nucleotide, alternate nucleotide, and PolyPhenol-2 prediction into PPH2 profiles 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pph2_data.to_csv('pph2_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPH2_profiles = []\n",
    "for row in range(len(pph2_data.values)):\n",
    "    profile = [pph2_data.values[row][0], \\\n",
    "    pph2_data.iloc[row,9], \\\n",
    "    pph2_data.iloc[row,10], \\\n",
    "    pph2_data.iloc[row,11]]    \n",
    "    # rsID, referenceNT, alternateNT, PPH2 prediction\n",
    "    PPH2_profiles += [profile]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take off last few lines which are not SNP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPH2_profiles = PPH2_profiles[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPH2_df = pd.DataFrame.from_records(PPH2_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFT_df = pd.DataFrame.from_records(SIFT_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPH2_df.to_csv('pph2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFT_df.to_csv('sift.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append main dataframe with predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matching requirement for both SIFT and PolyPhenol-2: rsID, refNT, and altNT (rsID alone not unique since >1 altNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPH2_profiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "complete_table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first making a tinier table with only necessary data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_df = complete_table\n",
    "column_list = ['Source',\n",
    "       'Filters - exomes', 'Filters - genomes', 'Consequence',\n",
    "       'Protein Consequence', 'Transcript Consequence', 'Annotation', 'Flags',\n",
    "       'Allele Count', 'Allele Number', 'Homozygote Count',\n",
    "       'Hemizygote Count', 'Allele Count African', 'Allele Number African',\n",
    "       'Homozygote Count African', 'Hemizygote Count African',\n",
    "       'Allele Count Latino', 'Allele Number Latino',\n",
    "       'Homozygote Count Latino', 'Hemizygote Count Latino',\n",
    "       'Allele Count Ashkenazi Jewish', 'Allele Number Ashkenazi Jewish',\n",
    "       'Homozygote Count Ashkenazi Jewish',\n",
    "       'Hemizygote Count Ashkenazi Jewish', 'Allele Count East Asian',\n",
    "       'Allele Number East Asian', 'Homozygote Count East Asian',\n",
    "       'Hemizygote Count East Asian', 'Allele Count European (Finnish)',\n",
    "       'Allele Number European (Finnish)',\n",
    "       'Homozygote Count European (Finnish)',\n",
    "       'Hemizygote Count European (Finnish)',\n",
    "       'Allele Count European (non-Finnish)',\n",
    "       'Allele Number European (non-Finnish)',\n",
    "       'Homozygote Count European (non-Finnish)',\n",
    "       'Hemizygote Count European (non-Finnish)', 'Allele Count Other',\n",
    "       'Allele Number Other', 'Homozygote Count Other',\n",
    "       'Hemizygote Count Other', 'Allele Count South Asian',\n",
    "       'Allele Number South Asian', 'Homozygote Count South Asian',\n",
    "       'Hemizygote Count South Asian']\n",
    "for column in column_list:\n",
    "    truncated_df = truncated_df.drop(column, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for matching requirement to fill in annotation columns in tinier table (rsID, refNT, and altNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SIFTrow in range(len(SIFT_df.values)):\n",
    "    for row in range(len(truncated_df.values)):\n",
    "        if truncated_df.iloc[row,2] == SIFT_df.iloc[SIFTrow,0] and \\\n",
    "        truncated_df.iloc[row,3] == SIFT_df.iloc[SIFTrow,1] and \\\n",
    "        truncated_df.iloc[row,4] == SIFT_df.iloc[SIFTrow,2]:\n",
    "            truncated_df.iloc[row,7] = SIFT_df.iloc[SIFTrow,3]\n",
    "for PPH2row in range(len(PPH2_profiles)):\n",
    "    for row in range(len(truncated_df.values)):\n",
    "        if truncated_df.iloc[row,2] == PPH2_df.iloc[PPH2row,0] and \\\n",
    "        truncated_df.iloc[row,3] == PPH2_df.iloc[PPH2row,1] and \\\n",
    "        truncated_df.iloc[row,4] == PPH2_df.iloc[PPH2row,2]:\n",
    "            truncated_df.iloc[row,8] = PPH2_df.iloc[PPH2row,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_df.to_csv('annotations_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add annotation part of tinier dataframe to master table, write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table.iloc[:,51:] = truncated_df.iloc[:,7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table.to_csv('with_SIFT_PPH2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIFT and PPH2 using rsIDs did not return anywhere near enough results for all the SNPs, so take two: VEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table = pd.read_csv('VEP_results.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table.to_csv('VEP_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VEP returned about 3x as many results as original data points, must remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table = VEP_table.drop('cDNA_position', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table = VEP_table.drop('CDS_position', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table = VEP_table.drop('EXON', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table = VEP_table[VEP_table.SYMBOL != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table = VEP_table[VEP_table.Codons != '-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table = VEP_table.drop_duplicates(subset=['#Uploaded_variation', 'Location', 'Allele'], keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table = VEP_table.set_index('SYMBOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table['gene'] = VEP_table.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write cleaned vegetable to CSV for record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEP_table.to_csv('veptable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add columns for SIFT and PPH2 annotations and also CADD but this time from the VEP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table['SIFT_from_VEP'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table['PPH2_from_VEP'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    frame.set_index('gene')\n",
    "    frame['SIFT_from_VEP'] = ''\n",
    "    frame['PPH2_from_VEP'] = ''\n",
    "    frame['CADD_SCALED'] = ''\n",
    "    frame['CADD'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go back to use individual frames for efficiency, when gene, rsID, and alternateNT match insert annotations from VEP table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for VEProw in range(len(VEP_table.values)):\n",
    "    for frame in frames:\n",
    "        if VEP_table.iloc[VEProw,36] == frame.iloc[0,56]: # match gene\n",
    "            for framerow in range(len(frame.values)): # match rsIDs nextline\n",
    "                if VEP_table.iloc[VEProw,0] == frame.iloc[framerow,2] and \\\n",
    "                VEP_table.iloc[VEProw,2] == frame.iloc[framerow,4]: # match alternateNT\n",
    "                    frame.iloc[framerow,51] = VEP_table.iloc[VEProw,23] # SIFT\n",
    "                    frame.iloc[framerow,52] = VEP_table.iloc[VEProw,24] # PPH2\n",
    "                    frame.iloc[framerow,54] = VEP_table.iloc[VEProw,35] # CADD\n",
    "                    frame.iloc[framerow,55] = VEP_table.iloc[VEProw,34] # CADD SCALED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "within individual frames re-sort by allele frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(frames)):\n",
    "    frames[x] = frames[x].sort_values('Allele Frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stick them back together to form master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table_2 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_table_2.to_csv('sortby_gene_annotated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe SIFT direct results to compare to VEP generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFT_scores_direct = pd.read_csv('SIFT individual proteins/SIFT-scores-SLC22A6.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFT_df = pd.DataFrame(SIFT_scores_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make dict for amino acids and alphabet abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_abb = {'ala':'a', 'cys':'c', 'asp':'d', 'glu':'e', 'phe':'f', 'gly':'g', \n",
    "          'his':'h', 'ile':'i', 'lys':'k', 'leu':'l', 'met':'m', 'asn':'n', \n",
    "          'pro':'p', 'gln':'q', 'arg':'r', 'ser':'s', 'thr':'t', 'val':'v', \n",
    "          'trp':'w', 'tyr':'y'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table_2 = pd.read_csv('SNPs_sortby_gene_annotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table_2['SIFT_direct'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFT_df.to_csv('sift_direct.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFT_df = pd.read_csv('sift_direct.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SIFTrow in range(len(SIFT_df.values)):\n",
    "    SIFT_position = SIFT_df.iloc[SIFTrow,0][:-6].lower()\n",
    "    #print(SIFT_position)\n",
    "    if SIFT_df.iloc[SIFTrow,0] != 'pos':\n",
    "        SIFT_ref_aa = SIFT_df.iloc[SIFTrow,0][-6].lower()\n",
    "    #print(SIFT_df.iloc[SIFTrow,0])\n",
    "    #print(SIFT_ref_aa)\n",
    "    for Mrow in range(372):\n",
    "        m_ref_aa = master_table_2.iloc[Mrow,9][2:5].lower()\n",
    "        #print(m_ref_aa)\n",
    "        m_alt_aa = master_table_2.iloc[Mrow,9][-3:].lower()\n",
    "        #print(m_alt_aa)\n",
    "        m_position = master_table_2.iloc[Mrow,9][5:-3]\n",
    "        #print(m_position)\n",
    "        if m_ref_aa in AA_abb.keys() and m_alt_aa in AA_abb.keys() \\\n",
    "        and AA_abb[m_ref_aa] == SIFT_ref_aa and SIFT_position == m_position:\n",
    "            amino_column = AA_abb[m_alt_aa].upper()\n",
    "            master_table_2.iloc[Mrow,56] = SIFT_df.loc[SIFTrow,amino_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_master_SIFT(csv, start_row, end_row):\n",
    "    SIFT_df = pd.read_csv(str('SIFT individual proteins/' + csv), sep='\\t')\n",
    "    for SIFTrow in range(len(SIFT_df.values)):\n",
    "        SIFT_position = SIFT_df.iloc[SIFTrow,0][:-6].lower()\n",
    "        #print(SIFT_position)\n",
    "        if SIFT_df.iloc[SIFTrow,0] != 'pos':\n",
    "            SIFT_ref_aa = SIFT_df.iloc[SIFTrow,0][-6].lower()\n",
    "        #print(SIFT_df.iloc[SIFTrow,0])\n",
    "        #print(SIFT_ref_aa)\n",
    "        for Mrow in range(start_row, end_row + 1):\n",
    "            m_ref_aa = master_table_2.iloc[Mrow,9][2:5].lower()\n",
    "            #print(m_ref_aa)\n",
    "            m_alt_aa = master_table_2.iloc[Mrow,9][-3:].lower()\n",
    "            #print(m_alt_aa)\n",
    "            m_position = master_table_2.iloc[Mrow,9][5:-3]\n",
    "            #print(m_position)\n",
    "            if m_ref_aa in AA_abb.keys() and m_alt_aa in AA_abb.keys() \\\n",
    "            and AA_abb[m_ref_aa] == SIFT_ref_aa and SIFT_position == m_position:\n",
    "                amino_column = AA_abb[m_alt_aa].upper()\n",
    "                master_table_2.iloc[Mrow,56] = SIFT_df.loc[SIFTrow,amino_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_master_SIFT('SIFT-scores-SLC22A7.txt', 6385, 6765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_master_SIFT('SIFT-scores-SLC22A8.txt',  370, 714)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_master_SIFT('SIFT-scores-SLC22A9.txt', 710, 1182)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_master_SIFT('SIFT-scores-SLC22A12.txt', 6760, 7149)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_master_SIFT('SIFT-scores-SLC51A.txt', 23870, 24153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table_2.to_csv('master_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
